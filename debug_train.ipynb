{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import random\n",
    "#import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "from torch.utils import data\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import scipy.misc\n",
    "import torch.backends.cudnn as cudnn\n",
    "import sys\n",
    "import os\n",
    "import os.path as osp\n",
    "from deeplab.model import Res_Deeplab\n",
    "from deeplab.loss import CrossEntropy2d\n",
    "from deeplab.datasets import VOCDataSet\n",
    "from deeplab.datasets import GenericDataset\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import *\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GenericDataset(data.Dataset):\n",
    "    def __init__(self, base_path, mode, transforms):\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        self.base_path = base_path\n",
    "        self.train_images = os.listdir(osp.join(base_path, 'train','images'))\n",
    "        self.train_masks= os.listdir(osp.join(base_path, 'train','masks'))\n",
    "        self.val_images = os.listdir(osp.join(base_path, 'val','images'))\n",
    "        self.val_masks = os.listdir(osp.join(base_path, 'val','masks'))\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.mode == 'train':\n",
    "            return len(self.train_images)\n",
    "\n",
    "        return len(self.val_images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train':\n",
    "            img = Image.open(osp.join(self.base_path, 'train','images',self.train_images[index]))\n",
    "            mask = Image.open(osp.join(self.base_path, 'train','masks',self.train_masks[index])).convert('L')\n",
    "            return self.transforms(img),self.transforms(mask),img.size,self.train_images[index]\n",
    "\n",
    "        img = Image.open(osp.join(self.base_path,'val','images',self.val_images[index]))\n",
    "        mask = Image.open(osp.join(self.base_path,'val','masks',self.val_masks[index])).convert('L')\n",
    "        return self.transforms(img),self.transforms(mask),img.size, self.val_images[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsize=321\n",
    "\n",
    "rgb_mean = (0.4914, 0.4822, 0.4465)\n",
    "rgb_std = (0.2023, 0.1994, 0.2010)\n",
    "# todo add augmentation\n",
    "train_transform = Compose([\n",
    "#                           transforms.RandomRotation(30),\n",
    "#                           RandomGamma(0.4, [0.8, 1.2]),\n",
    "#                          RandomScale(0.4, [0.5, 0.8, 1.5, 2.0]),\n",
    "#                           RandomCompression(0.4, [70, 90]),\n",
    "                           #RandomCrop(224),\n",
    "                           Resize((tsize, tsize)),\n",
    "                          ToTensor(),\n",
    "#                           Normalize(rgb_mean, rgb_std)\n",
    "                           ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "DATA_DIRECTORY = '/home/dhc/nevus_masks/'\n",
    "DATA_LIST_PATH = './dataset/list/train_aug.txt'\n",
    "IGNORE_LABEL = 255\n",
    "INPUT_SIZE = '321,321'\n",
    "LEARNING_RATE = 2.5e-4\n",
    "MOMENTUM = 0.9\n",
    "NUM_CLASSES = 1\n",
    "NUM_STEPS = 20000\n",
    "POWER = 0.9\n",
    "RANDOM_SEED = 1234\n",
    "RESTORE_FROM = './dataset/MS_DeepLab_resnet_pretrained_COCO_init.pth'\n",
    "SAVE_NUM_IMAGES = 2\n",
    "SAVE_PRED_EVERY = 1000\n",
    "SNAPSHOT_DIR = './snapshots/'\n",
    "WEIGHT_DECAY = 0.0005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1x_lr_params_NOscale(model):\n",
    "    \"\"\"\n",
    "    This generator returns all the parameters of the net except for \n",
    "    the last classification layer. Note that for each batchnorm layer, \n",
    "    requires_grad is set to False in deeplab_resnet.py, therefore this function does not return \n",
    "    any batchnorm parameter\n",
    "    \"\"\"\n",
    "    b = []\n",
    "\n",
    "    b.append(model.conv1)\n",
    "    b.append(model.bn1)\n",
    "    b.append(model.layer1)\n",
    "    b.append(model.layer2)\n",
    "    b.append(model.layer3)\n",
    "    b.append(model.layer4)\n",
    "\n",
    "    \n",
    "    for i in range(len(b)):\n",
    "        for j in b[i].modules():\n",
    "            jj = 0\n",
    "            for k in j.parameters():\n",
    "                jj+=1\n",
    "                if k.requires_grad:\n",
    "                    yield k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_10x_lr_params(model):\n",
    "    \"\"\"\n",
    "    This generator returns all the parameters for the last layer of the net,\n",
    "    which does the classification of pixel into classes\n",
    "    \"\"\"\n",
    "    b = []\n",
    "    b.append(model.layer5.parameters())\n",
    "\n",
    "    for j in range(len(b)):\n",
    "        for i in b[j]:\n",
    "            yield i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, i_iter):\n",
    "    \"\"\"Sets the learning rate to the initial LR divided by 5 at 60th, 120th and 160th epochs\"\"\"\n",
    "    lr = lr_poly(1e-4, i_iter, 20000, 5)\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    optimizer.param_groups[1]['lr'] = lr * 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lr_poly(base_lr, iter, max_iter, power):\n",
    "    return base_lr*((1-float(iter)/max_iter)**(power))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_calc(pred, label):\n",
    "    \"\"\"\n",
    "    This function returns cross entropy loss for semantic segmentation\n",
    "    \"\"\"\n",
    "    #print(str(pred), str(label))\n",
    "    # out shape batch_size x channels x h x w -> batch_size x channels x h x w\n",
    "    # label shape h x w x 1 x batch_size  -> batch_size x 1 x h x w\n",
    "    label = Variable(label.long()).cuda()\n",
    "    #criterion = torch.nn.BCELoss().cuda(gpu)\n",
    "    criterion = CrossEntropy2d().cuda()\n",
    "    #criterion = nn.CrossEntropyLoss().cuda(gpu)\n",
    "    \n",
    "    #return cross_entropy2d(pred.view(8,1,321,321), label.view(8,1,321,321))\n",
    "    return criterion(pred, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1), ceil_mode=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer5): Classifier_Module(\n",
       "    (conv2d_list): ModuleList(\n",
       "      (0): Conv2d(2048, 2, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "      (1): Conv2d(2048, 2, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "      (2): Conv2d(2048, 2, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "      (3): Conv2d(2048, 2, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Res_Deeplab(num_classes=2)\n",
    "model.train()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_state_dict = torch.load('snapshots/VOC12_scenes_400.pth')\n",
    "new_params = model.state_dict().copy()\n",
    "#for i in saved_state_dict:\n",
    "    #Scale.layer5.conv2d_list.3.weight\n",
    "#    i_parts = i.split('.')\n",
    "    # print i_parts\n",
    "#    if not num_classes == 21 or not i_parts[1]=='layer5':\n",
    "#        new_params['.'.join(i_parts[1:])] = saved_state_dict[i]\n",
    "model.load_state_dict(new_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GenericDataset(DATA_DIRECTORY,'train', train_transform)\n",
    "trainloader = data.DataLoader(dataset, batch_size = 8, shuffle=True, num_workers = 4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD([{'params': get_1x_lr_params_NOscale(model), 'lr': 1e-4 }, \n",
    "                       {'params': get_10x_lr_params(model), 'lr': 10*1e-4}], \n",
    "                      lr=1e-4, momentum=0.9,weight_decay=0.00001)\n",
    "#    optimizer = optim.Adam(get_10x_lr_params(model), lr=1e-5)\n",
    "optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 321,321"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = nn.Upsample(size=input_size, mode='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "topil = ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels ,_,_ = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = Variable(imgs).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = model(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 41, 41])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = interp(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigm_t = F.sigmoid(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "simg_t_l1 = sigm_t[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 321, 321])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUEAAAFBCAAAAADMZULtAAAEeElEQVR4nO3cXWhbZRzH8X9ykrYJXdM5u3am0zp2o4OxqVX0wksFFQQRb7wXXxB2MVR0V17MSy+88WaKUkEUFFFQRJgM2VZQmdsUtuHclmHb6WjW9SU5bfJ4Y6p9SZqcp+3/f8L3c9XmhfPjl+c5zznJSUQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD8JbQDNNDbX/vrxrhmjsZS2gEaePJw7fX9+GBVNUkjlhvM7qg1mFPN0ZjRBocfTYgML/6775D7968zX7jVn4GlXq661Y0E2tGWszgG00MdA/Xuy91dFRGpXCptXp7GLK7F+c/vyHbXua80JSIixafPbF6exiyOwWDb9rr3dXWJiEjKTm47SWoefKxn65oPyrw4fvZTu0c4ug7UWUOW+8TIi28kRk2wLehp8qFdOxZESpMbGqcZxlaS/If5rfV3gkvcHHMi3x1Y2NhAazM2BtO7hpp96JYtIvKb/ggw1eDDj+fWXkSW2HN49siVjQkTSwebXET+r/iAcmg7YzDVF0R5AyG5fbB0nXNlEZGdxy78HWEMVgoX3k1r5rYzBtNDO6M8LTmovJwkNTfeFmjQl5VZnOvNR46Svb18rbyeYWLphYuF+QjriHPOuZk/Tt+jl9zMGLwz+nOzQ1Od65ekVSYazD3V/ZB2hshMNNj35qB2hOjaYy1O5ncN6L/HoGh3IeoiUjsxGb/8fodSeBOz2FuyX/q0xmB7zGJNNOjLwCzOZHrj/DoaaPDZlzr6tDN4MNDgwD7tBF7iPH9soEFfNOiLBn3RoC8Da/E6KI9cPV9R2nabNHjkhNq2mcW+aNAXDfpqh/1g4fuZv/S23g4NnnouVLz0qB0adFXNa9LZD/qiQV+xn8XhN9d+Uf1iSewbnHtrVFQvYdVuMJlNeF7z4pQvAdZuMP/OrZEuXbVDu8HM8G3KCXxpN1j8IHff/dGffvHb2Yn1CxNXhzwumPlM9TJ+EeF40B8N+qJBX9oriY/5k8Uf9b/nHucGZ179qar1+dJ/4ttgOHOjFGqHkDg3eOyN8Lx2BpE4Nzj5s/oPBIhIbBsMfyiOGvlScUwbnH7tlIFFRERMNDh3Pehp7bC0PD1Zmt+gNHHUv/eJ8dbOhr/evyejnXqRgTE4MTHb4oAqnjYyg0VMNCgy/eUtd+1t7qGXR53ICSOLiB2JIPV6kxP4o85UKmXqVxxNjEFXkabOb13owgVDE1hEjDTYrKlXLo3pv5WwTKwaDI+f1Y6wkpUGfx3pfiRb997fTzoRkZvFzYoTQ4lg95X668d76SAIgsDUClJjZQy6SmVuNr3K50YLoYiUK+Z2f4vsfLc+s7/zmedX3vzV205k7JzdI0ArY1Bk7rjcu8rNfx61W56IWGpQRApHV952bvNjtMbOLBaRuvtBAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMBa/gHEBZI/jdgJPwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=321x321 at 0x7F2DB62D0358>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topil(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigm_t_l1_cpu = simg_t_l1.cpu().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigm_t_l1_cpu_np = sigm_t_l1_cpu[0].round().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 321, 321])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigm_t_l1_cpu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a94798ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sigm_t_l1_cpu_np)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvc = t.cpu().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 321, 321])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvc.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 41, 41])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvc.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "torch.LongTensor constructor received an invalid combination of arguments - got (torch.FloatTensor), but expected one of:\n * no arguments\n * (int ...)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m)\n * (torch.LongTensor viewed_tensor)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m)\n * (torch.Size size)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m)\n * (torch.LongStorage data)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m)\n * (Sequence data)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-6e09f4825860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtopil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtvc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: torch.LongTensor constructor received an invalid combination of arguments - got (torch.FloatTensor), but expected one of:\n * no arguments\n * (int ...)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m)\n * (torch.LongTensor viewed_tensor)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m)\n * (torch.Size size)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m)\n * (torch.LongStorage data)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m)\n * (Sequence data)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtorch.FloatTensor\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "topil(torch.LongTensor(tvc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/THC/generated/../THCReduceAll.cuh:339",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a391601bf52b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#pred = pred.sum(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0;31m# eventually is in-place (so can't rely on automatically broadcasting)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mgrad_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnew_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m             \u001b[0mgrad_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m             \u001b[0mgrad_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_unexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mmasked_scatter\u001b[0;34m(self, mask, variable)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmasked_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_scatter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (59) : device-side assert triggered at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/THC/generated/../THCReduceAll.cuh:339"
     ]
    }
   ],
   "source": [
    "for i_iter, batch in enumerate(trainloader):\n",
    "    images, labels, _, _ = batch\n",
    "    images = Variable(images).cuda()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    adjust_learning_rate(optimizer, i_iter)\n",
    "    pred = interp(model(images))\n",
    "    #pred = pred.sum(1)\n",
    "    loss = loss_calc(pred, labels.squeeze())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('iter = ', i_iter, 'of', 20000,'completed, loss = ', loss.data.cpu().numpy())\n",
    "\n",
    "    if i_iter >= 19999:\n",
    "        print('save model ...')\n",
    "        torch.save(model.state_dict(),osp.join('snapshots', 'VOC12_scenes_'+str(20000)+'.pth'))\n",
    "#            break\n",
    "\n",
    "    if i_iter % 200 == 0 and i_iter!=0:\n",
    "        print('taking snapshot ...')\n",
    "        torch.save(model.state_dict(),osp.join('snapshots', 'VOC12_scenes_'+str(i_iter)+'.pth'))     \n",
    "\n",
    "end = timeit.default_timer()\n",
    "print(end-start,'seconds')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
